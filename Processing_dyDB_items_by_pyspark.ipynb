{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n@Author: Vighnesh Harish Bilgi\\n@Date: 2022-11-22\\n@Last Modified by: Vighnesh Harish Bilgi\\n@Last Modified time: 2022-11-22\\n@Title : Fetch and Process Tweet items from DynamoDB table using PySpark\\n\\n'"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "@Author: Vighnesh Harish Bilgi\n",
    "@Date: 2022-11-22\n",
    "@Last Modified by: Vighnesh Harish Bilgi\n",
    "@Last Modified time: 2022-11-22\n",
    "@Title : Fetch and Process Tweet items from DynamoDB table using PySpark\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['AWS_DEFAULT_REGION'] = 'us-east-1'\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = os.environ.get('test1_access_key')\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = os.environ.get('test1_secret_access_key')\n",
    "TABLE_NAME = 'WorldCup2022Tweets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading DynamoDB items into RDD \n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local\").appName(\"Reading DynamoDB items into RDD \").getOrCreate()\n",
    "print(spark.sparkContext.appName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading items from DynamoDB Table into a list of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prinitng Every Item in the table:\n"
     ]
    }
   ],
   "source": [
    "dyDB =  boto3.resource('dynamodb')   \n",
    "\n",
    "table = dyDB.Table(TABLE_NAME)\n",
    "\n",
    "table_details = table.scan()\n",
    "table_items = table_details['Items']\n",
    "\n",
    "list_of_dict = []\n",
    "# appending all items/dictionaries from the table to a list\n",
    "for item in table_items:\n",
    "    # print(item)\n",
    "    list_of_dict.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\apps\\spark-3.0.0-bin-hadoop2.7\\python\\pyspark\\sql\\session.py:378: UserWarning: inferring schema from dict is deprecated,please use pyspark.sql.Row instead\n",
      "  warnings.warn(\"inferring schema from dict is deprecated,\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------------+--------------------+-------------------+---------------+--------------------+-----------------------+\n",
      "|    ArrivalTimestamp|        display_name|           tweet_id|          tweet_text|            user_id|      user_name|  word_count_on_text|word_occurences_on_text|\n",
      "+--------------------+--------------------+-------------------+--------------------+-------------------+---------------+--------------------+-----------------------+\n",
      "|2022-11-22 12:51:...|                Rags|1594954296491409409|@INSIGHTUK2 Even ...|1456973849082224646|      rhalharvi|19.00000000000000...|   19.00000000000000...|\n",
      "|2022-11-22 12:54:...|         Andy Newton|1594954908859596800|World Cup Betting...|           68403698| NewtsDailyLays|16.00000000000000...|   16.00000000000000...|\n",
      "|2022-11-22 12:50:...|        MODI FOREVER|1594953972326227968|RT @gnuseibeh: Qa...|          163162895| royprateek2010|24.00000000000000...|   24.00000000000000...|\n",
      "|2022-11-22 12:46:...|           GKT⚽JJK💜|1594952993954496512|RT @FahadAlkubais...|1291957477408272384|   lovelykana23|25.00000000000000...|   25.00000000000000...|\n",
      "|2022-11-22 12:41:...|Kumar Gaurav #Gla...|1594951772044668928|RT @gnuseibeh: Qa...|         1528472935|gauravkumar1508|24.00000000000000...|   24.00000000000000...|\n",
      "|2022-11-22 12:52:...|         Jo Geissler|1594954407086813184|@ThomasHitz @Virg...| 817098678037020673|    geissler_jo|19.00000000000000...|   19.00000000000000...|\n",
      "|2022-11-22 12:48:...|       manishnajkani|1594953468888113152|@Unimoni_India 🔥...|1180840929382600704| manishnajkani1|18.00000000000000...|   18.00000000000000...|\n",
      "|2022-11-22 12:50:...|                Mila|1594954051506298880|RT @INSIGHTUK2: \"...|1591424514725814273|   Mila78604235|23.00000000000000...|   23.00000000000000...|\n",
      "|2022-11-22 12:44:...|              tarkam|1594952536863444993|@LauraMcAllister ...|1148352210327261185|  tarkamAtLarge|52.00000000000000...|   52.00000000000000...|\n",
      "|2022-11-22 12:44:...|     Md Nayeem Hasan|1594952340142182400|RT @BitMart_Futur...|1468416268294582278| Nayeemhasan121|22.00000000000000...|   22.00000000000000...|\n",
      "+--------------------+--------------------+-------------------+--------------------+-------------------+---------------+--------------------+-----------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df = spark.createDataFrame(list_of_dict)\n",
    "spark_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------+--------------------+-----------------------+\n",
      "|summary|    ArrivalTimestamp|        display_name|            tweet_id|          tweet_text|             user_id|    user_name|  word_count_on_text|word_occurences_on_text|\n",
      "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------+--------------------+-----------------------+\n",
      "|  count|                1004|                1004|                1004|                1004|                1004|         1004|                1004|                   1004|\n",
      "|   mean|                null|                null|1.594953288752600...|                null|1.082297965066966...|         null|21.49302788844621...|   21.49302788844621...|\n",
      "| stddev|                null|                null|1.034527046427790...|                null|5.975100107108737...|         null|   7.634532920648764|      7.634532920648764|\n",
      "|    min|2022-11-22 12:40:...|            # Tejesh| 1594951523317981184|#Iran players pro...| 1007121392054095872|   09_hickory|2.000000000000000000|   2.000000000000000000|\n",
      "|    max|2022-11-22 12:55:...|🧊Bancuhcrypto.me...| 1594955124069535745|🚨At the #WorldCu...|           999108734|zjiouo17qob__|60.00000000000000...|   60.00000000000000...|\n",
      "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------+--------------------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------+--------------------+-----------------------+\n",
      "|summary|    ArrivalTimestamp|        display_name|            tweet_id|          tweet_text|             user_id|    user_name|  word_count_on_text|word_occurences_on_text|\n",
      "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------+--------------------+-----------------------+\n",
      "|  count|                1004|                1004|                1004|                1004|                1004|         1004|                1004|                   1004|\n",
      "|   mean|                null|                null|1.594953288752600...|                null|1.082297965066966...|         null|21.49302788844621...|   21.49302788844621...|\n",
      "| stddev|                null|                null|1.034527046427790...|                null|5.975100107108737...|         null|   7.634532920648764|      7.634532920648764|\n",
      "|    min|2022-11-22 12:40:...|            # Tejesh| 1594951523317981184|#Iran players pro...| 1007121392054095872|   09_hickory|2.000000000000000000|   2.000000000000000000|\n",
      "|    25%|                null|                null|1.594952383477387...|                null|8.554253340065669...|         null|                19.0|                   19.0|\n",
      "|    50%|                null|                null|1.594953325094789...|                null|1.383094905816375...|         null|                21.0|                   21.0|\n",
      "|    75%|                null|                null|1.594954168602599...|                null|1.513399906052055...|         null|                24.0|                   24.0|\n",
      "|    max|2022-11-22 12:55:...|🧊Bancuhcrypto.me...| 1594955124069535745|🚨At the #WorldCu...|           999108734|zjiouo17qob__|60.00000000000000...|   60.00000000000000...|\n",
      "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------+--------------------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.summary().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ArrivalTimestamp: string (nullable = true)\n",
      " |-- display_name: string (nullable = true)\n",
      " |-- tweet_id: string (nullable = true)\n",
      " |-- tweet_text: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- user_name: string (nullable = true)\n",
      " |-- word_count_on_text: decimal(38,18) (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dropping last column\n",
    "spark_df = spark_df.drop(\"word_occurences_on_text\")\n",
    "spark_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ArrivalTimestamp: string (nullable = true)\n",
      " |-- display_name: string (nullable = true)\n",
      " |-- tweet_id: string (nullable = true)\n",
      " |-- tweet_text: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- user_name: string (nullable = true)\n",
      " |-- word_count_on_text: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Changing data types of 'word count on text' to integer\n",
    "spark_df = spark_df.withColumn(\"word_count_on_text\",spark_df.word_count_on_text.cast('int'))\n",
    "spark_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ArrivalTimestamp: string (nullable = true)\n",
      " |-- display_name: string (nullable = true)\n",
      " |-- tweet_id: string (nullable = true)\n",
      " |-- tweet_text: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- user_name: string (nullable = true)\n",
      " |-- word_count_on_text: integer (nullable = true)\n",
      " |-- Timestamp: string (nullable = true)\n",
      "\n",
      "+--------------------------------+-------------------+\n",
      "|ArrivalTimestamp                |Timestamp          |\n",
      "+--------------------------------+-------------------+\n",
      "|2022-11-22 12:51:58.145000+05:30|2022-11-22 12:51:58|\n",
      "|2022-11-22 12:54:24.462000+05:30|2022-11-22 12:54:24|\n",
      "|2022-11-22 12:50:40.345000+05:30|2022-11-22 12:50:40|\n",
      "|2022-11-22 12:46:47.176000+05:30|2022-11-22 12:46:47|\n",
      "|2022-11-22 12:41:56.082000+05:30|2022-11-22 12:41:56|\n",
      "|2022-11-22 12:52:24.573000+05:30|2022-11-22 12:52:24|\n",
      "|2022-11-22 12:48:40.395000+05:30|2022-11-22 12:48:40|\n",
      "|2022-11-22 12:50:59.093000+05:30|2022-11-22 12:50:59|\n",
      "|2022-11-22 12:44:58.143000+05:30|2022-11-22 12:44:58|\n",
      "|2022-11-22 12:44:11.335000+05:30|2022-11-22 12:44:11|\n",
      "+--------------------------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Removing the milliseconds part of ArrivalTimestamp\n",
    "spark_df = spark_df.withColumn('Timestamp', substring('ArrivalTimestamp', 1,19))\n",
    "# spark_df = spark_df.withColumn('Timestamp', split(spark_df['ArrivalTimestamp'], '.').getItem(0)).withColumn('milliseconds', split(spark_df['ArrivalTimestamp'], '.').getItem(1))\n",
    "# spark_df = spark_df.drop(\"milliseconds\")\n",
    "spark_df.printSchema()\n",
    "spark_df.select('ArrivalTimestamp','Timestamp').show(10, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ArrivalTimestamp: string (nullable = true)\n",
      " |-- display_name: string (nullable = true)\n",
      " |-- tweet_id: string (nullable = true)\n",
      " |-- tweet_text: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- user_name: string (nullable = true)\n",
      " |-- word_count_on_text: integer (nullable = true)\n",
      " |-- Timestamp: string (nullable = true)\n",
      " |-- Timestamp_2: timestamp (nullable = true)\n",
      "\n",
      "+--------------------------------+-------------------+-------------------+\n",
      "|ArrivalTimestamp                |Timestamp          |Timestamp_2        |\n",
      "+--------------------------------+-------------------+-------------------+\n",
      "|2022-11-22 12:51:58.145000+05:30|2022-11-22 12:51:58|2022-11-22 12:51:58|\n",
      "|2022-11-22 12:54:24.462000+05:30|2022-11-22 12:54:24|2022-11-22 12:54:24|\n",
      "|2022-11-22 12:50:40.345000+05:30|2022-11-22 12:50:40|2022-11-22 12:50:40|\n",
      "|2022-11-22 12:46:47.176000+05:30|2022-11-22 12:46:47|2022-11-22 12:46:47|\n",
      "|2022-11-22 12:41:56.082000+05:30|2022-11-22 12:41:56|2022-11-22 12:41:56|\n",
      "|2022-11-22 12:52:24.573000+05:30|2022-11-22 12:52:24|2022-11-22 12:52:24|\n",
      "|2022-11-22 12:48:40.395000+05:30|2022-11-22 12:48:40|2022-11-22 12:48:40|\n",
      "|2022-11-22 12:50:59.093000+05:30|2022-11-22 12:50:59|2022-11-22 12:50:59|\n",
      "|2022-11-22 12:44:58.143000+05:30|2022-11-22 12:44:58|2022-11-22 12:44:58|\n",
      "|2022-11-22 12:44:11.335000+05:30|2022-11-22 12:44:11|2022-11-22 12:44:11|\n",
      "+--------------------------------+-------------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert Timestamp column of type string into type timestamp \n",
    "spark_df = spark_df.withColumn(\"Timestamp_2\",to_timestamp(\"Timestamp\"))\n",
    "spark_df.printSchema()\n",
    "spark_df.select('ArrivalTimestamp','Timestamp','Timestamp_2').show(10, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- tweet_id: string (nullable = true)\n",
      " |-- Timestamp: timestamp (nullable = true)\n",
      " |-- display_name: string (nullable = true)\n",
      " |-- user_name: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- tweet_text: string (nullable = true)\n",
      " |-- word_count_on_text: integer (nullable = true)\n",
      "\n",
      "+-------------------+-------------------+----------------------------------+---------------+-------------------+--------------------+------------------+\n",
      "|           tweet_id|          Timestamp|                      display_name|      user_name|            user_id|          tweet_text|word_count_on_text|\n",
      "+-------------------+-------------------+----------------------------------+---------------+-------------------+--------------------+------------------+\n",
      "|1594951526619176961|2022-11-22 12:40:57|                           resa_ds|      leyla_677| 965136351455715328|RT @AmnestyIran: ...|                23|\n",
      "|1594951523317981184|2022-11-22 12:40:58|                              O.G.|  whatisgooding|         3451959143|I’m sorry, but #L...|                33|\n",
      "|1594951524769300480|2022-11-22 12:40:58|                      هەموو ژیناین|       zhinakan|1462890041437474817|Isalamic Republic...|                36|\n",
      "|1594951525843013633|2022-11-22 12:40:58|                   SPORTSCONTINENT|SPORTSCONTINEN2|1345500487374811137|NETHERLANDS 🇳🇱 ...|                15|\n",
      "|1594951529488060416|2022-11-22 12:40:58|                         Newbiland|      newbiland|1483936314110406656|RT @binary_x: ❓Wh...|                20|\n",
      "|1594951532398940160|2022-11-22 12:40:59|                      Rey Quraishi|        rey_qur|          358769498|Started as a “10”...|                30|\n",
      "|1594951534437187586|2022-11-22 12:40:59|                       Shahbaz Ali|  Shahbaz033432|1369619773106098176|@TopGoal_NFT Arge...|                 3|\n",
      "|1594951544495304704|2022-11-22 12:41:01|                             Billa|       Billa032|1593402442393489408|RT @RoadQatar_WC:...|                20|\n",
      "|1594951545069658117|2022-11-22 12:41:02|                        Zain Bajwa|  Zain_BajwaPTI|1505203001702686721|Weldon @qatar\n",
      "You...|                26|\n",
      "|1594951545849888768|2022-11-22 12:41:02|                           HQ VITA|         HQVita|1200810243372015617|• THREAD\n",
      "\n",
      "Argenti...|                17|\n",
      "|1594951550035955712|2022-11-22 12:41:03|                   Yiannis Mamakis|     yiannism80|          238065523|RT @TopGoal_NFT: ...|                19|\n",
      "|1594951550400712704|2022-11-22 12:41:03|                       Imen maamir|     ImenMaamir|1588642494413213696|@gate_io or $DUCK...|                32|\n",
      "|1594951552766447616|2022-11-22 12:41:03|ラテマエ@インデックス投資 時々 ...|   lattemaestro|1007121392054095872|RT @TopGoal_NFT: ...|                19|\n",
      "|1594951556658610176|2022-11-22 12:41:04|              Greatest Hits Rad...|     GHRNorfolk|           78933122|In the news with ...|                41|\n",
      "|1594951564069949441|2022-11-22 12:41:06|                      هەموو ژیناین|       zhinakan|1462890041437474817|Isalamic Republic...|                36|\n",
      "|1594951574950121474|2022-11-22 12:41:09|              🧊Bancuhcrypto.me...|   bancuhcrypto|1503408509756403715|RT @IOTASoccerTea...|                22|\n",
      "|1594951576124542976|2022-11-22 12:41:09|                      Amy Guettler|  saltedbayonet|          118870812|RT @TaylorMaydeuk...|                23|\n",
      "|1594951583913377793|2022-11-22 12:41:11|                        iChongqing|iChongqing_CIMC|1022324783428526080|Where's the fan o...|                37|\n",
      "|1594951598572437505|2022-11-22 12:41:15|                   Robert Quintero|RobQuintero9200|1560853965478080518|#Qatar2022 #World...|                14|\n",
      "|1594951601491709953|2022-11-22 12:41:15|                          Prof KKC|   KaranjaKeita|         3322895986|RT @Sea__Solitude...|                16|\n",
      "+-------------------+-------------------+----------------------------------+---------------+-------------------+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dropping ArrivalTimestamp and Timestamp column, renaming Timestamp_2 to Timestamp , reordering columns and then orders DF by Timestamp and then tweet_id\n",
    "spark_df = spark_df.drop(\"ArrivalTimestamp\", \"Timestamp\")\n",
    "spark_df = spark_df.withColumnRenamed(\"Timestamp_2\",\"Timestamp\")\n",
    "spark_df = spark_df.select(\"tweet_id\",\"Timestamp\",\"display_name\",\"user_name\",\"user_id\",\"tweet_text\",\"word_count_on_text\")\n",
    "spark_df = spark_df.sort(col(\"Timestamp\"),col(\"tweet_id\"))\n",
    "spark_df.printSchema()\n",
    "spark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_rdd = spark_df.rdd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
